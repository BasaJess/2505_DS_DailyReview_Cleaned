
# Day 14-16, 13-17.02.2025

Great work everybody for completing the first project! Now we are getting ready to dive deeper! 


---
## __Basic Overview__ 
 

*  We finished our first EDA for a fictional client on our own
*  Solved the issue of finding hypotheses 
*  Practiced EDA tasks such as data cleaning and visualization

---
##  __Schedule__


*  Day 1: Finding hypotheses till 3pm and starting to clean data
*  Day 2: Working independently on our EDA
*  Day 3: Finishing touches and presentation at 1.30pm


---
##  __EDA takeaways__

Working with this dataset we achieved:

- practiced acquiring data from a database
- practiced cleaning a database 
- learning new libraries, especially for geographical data  
    - [Folium](https://python-visualization.github.io/folium/latest/# "Folium")
    - [Geopy](https://geopy.readthedocs.io/en/stable/ "Geopy")
- getting feedback about presentation, design choices and visualization efforts
- practiced working for a customer, identifying needs and focussing on storytelling


---
#  __Outlook for the next days__


In the next days we will have a look at the following topics:

- Linear Regression
- Feature Engineering
- Bias-Variance-Tradeoff + Regularization
- Gradient Descent

Since a deeper understanding of statistic concepts and methods is helpful for these topics, we received notebooks. The first shows code for the calculation of different correlation coefficients and the second gives insight in test types

---

## __Overview of correlation coefficients__

Correlation coefficients are statistical measures that quantify the strength and direction of the relationship between two variables.

#### 1. Pearson Correlation Coefficient (r)  
- **Use:** Measures linear relationships between two continuous variables.  
- **Range:** -1 to +1.  
- **Best for:** Normally distributed data with linear patterns.  
- **Formula:**  
  r = Σ[(xᵢ - x̄)(yᵢ - ȳ)] / √[Σ(xᵢ - x̄)² Σ(yᵢ - ȳ)²]  
---

#### 2. Spearman’s Rank Correlation (ρ or rs)  
- **Use:** Measures monotonic relationships (increasing or decreasing trends).  
- **Range:** -1 to +1.  
- **Best for:** Non-linear relationships or ordinal data.  
- **Formula (using ranks):**  
  ρ = 1 - [6 Σdᵢ² / n(n² - 1)]  
  *where dᵢ is the difference between ranks.*
---

#### 3. Kendall’s Tau (τ)  
- **Use:** Measures ordinal association based on pairwise concordance.  
- **Range:** -1 to +1.  
- **Best for:** Small datasets with many tied ranks.  
- **Formula:**  
  τ = (Number of concordant pairs - Number of discordant pairs) / [n(n-1)/2]

---

#### 4. Point-Biserial Correlation  
- **Use:** Measures correlation between one continuous and one binary variable.  
- **Range:** -1 to +1.  
- **Best for:** Analyzing relationships like pass/fail vs. test scores.  
- **Formula:** Similar to Pearson correlation but adapted for binary data.

---

#### 5. Intraclass Correlation Coefficient (ICC)  
- **Use:** Measures consistency or agreement in repeated measures or between raters.  
- **Range:** 0 to 1.  
- **Best for:** Evaluating model reliability or annotator agreement.  
- **Types:** ICC(1), ICC(2), ICC(3) for different use cases.

---

**Key Takeaways:**  
- Use **Pearson** for linear, continuous relationships.  
- Use **Spearman** or **Kendall** for non-linear or ordinal data.  
- Use **Point-Biserial** for binary vs. continuous variables.  
- Use **ICC** for assessing reliability and agreement.

---

## __Overview of Hypothesis Testing__

Hypothesis testing is a statistical method used to make decisions or draw conclusions about a population based on a sample, by evaluating whether there is enough evidence to support a specific claim or hypothesis.
-> helps to distinguish between correlation and coincidence (statistical noise)

---

#### 1. **Z-Test**  
- **Use:** Tests population means when the sample size is large (n > 30) and variance is known.

---

#### 2. **T-Test**  
- **Use:** Compares means when the sample size is small or variance is unknown.  
  - **One-sample:** Compares sample mean to population mean.  
  - **Two-sample:** Compares means of two independent groups.  
  - **Paired:** Compares means from the same group before and after treatment.  

---

#### 3. **Chi-Square Test**  
- **Use:** Tests relationships between categorical variables.  
  - **Goodness of Fit:** Compares observed frequencies to expected frequencies.  
  - **Independence:** Tests if two categorical variables are related.  

---

#### 4. **ANOVA (Analysis of Variance)**  
- **Use:** Compares means across three or more groups.  
  - **One-way ANOVA:** One independent variable.  
  - **Two-way ANOVA:** Two independent variables.  

---

#### 5. **Mann-Whitney U Test**  
- **Use:** Non-parametric test comparing two independent groups (alternative to t-test for non-normal data).  

---

#### 6. **Wilcoxon Signed-Rank Test**  
- **Use:** Non-parametric test comparing two related samples (alternative to paired t-test).  

---

#### 7. **Kruskal-Wallis Test**  
- **Use:** Non-parametric test comparing three or more groups (alternative to ANOVA for non-normal data).  

---

#### 8. **F-Test**  
- **Use:** Compares variances between two groups (often a precursor to ANOVA).  

---

 **Quick Guide:**  
- **Means (numeric):** Use **t-test**, **ANOVA**, **Mann-Whitney**, **Wilcoxon**.  
- **Categorical:** Use **Chi-square**.  
- **Variances:** Use **F-test**.  
- **Non-parametric:** Use **Mann-Whitney**, **Wilcoxon**, **Kruskal-Wallis**.  

For nice output in Hypothesis testing, consider this Python module:
[Statsmodels](https://geopy.readthedocs.io/en/stable/ "Statsmodels")

![Flowchart](https://www.scribbr.com/wp-content/uploads/2020/01/flowchart-for-choosing-a-statistical-test-993x1024.png)
